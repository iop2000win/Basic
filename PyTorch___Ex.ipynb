{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0a9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a69d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = datasets.load_boston()\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "X, y = data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a26fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X)\n",
    "# y = torch.FloatTensor(y).unsqueeze(-1)\n",
    "y = torch.FloatTensor(y).view(-1, 1) # reshape 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72423c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization - (X - 평균) / 표준편차\n",
    "X = (X - torch.mean(X)) / torch.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8f213",
   "metadata": {},
   "source": [
    "### 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24b867d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(13, 1) # 선형 회귀 모델\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56b5045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, X, y):\n",
    "    # 초기화\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    hypothesis = model(X) # 가설...?\n",
    "    \n",
    "    loss = criterion(hypothesis, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7494da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 114.2711\n",
      "epoch: 20, loss: 97.4869\n",
      "epoch: 30, loss: 88.4511\n",
      "epoch: 40, loss: 82.6769\n",
      "epoch: 50, loss: 78.9274\n",
      "epoch: 60, loss: 76.4395\n",
      "epoch: 70, loss: 74.7396\n",
      "epoch: 80, loss: 73.5334\n",
      "epoch: 90, loss: 72.6382\n",
      "epoch: 100, loss: 71.9405\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52cf37",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d88ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = data_set['data'], data_set['target']\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0490be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(30, 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.BCELoss() # binary cross entropy\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8a15a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, X, y):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    loss = criterion(hypothesis, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88a520f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.5725\n",
      "epoch: 20, loss: 0.5093\n",
      "epoch: 30, loss: 0.4635\n",
      "epoch: 40, loss: 0.4289\n",
      "epoch: 50, loss: 0.4019\n",
      "epoch: 60, loss: 0.3804\n",
      "epoch: 70, loss: 0.3627\n",
      "epoch: 80, loss: 0.3481\n",
      "epoch: 90, loss: 0.3357\n",
      "epoch: 100, loss: 0.3250\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6656c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "y_predicted = (model(X) >= 0.5).float()\n",
    "\n",
    "score = (y_predicted == y).float().mean()\n",
    "print('accuracy: {:.2f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c2c21",
   "metadata": {},
   "source": [
    "### 클래스를 이용한 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "280096b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 선형 회귀 모델\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        # 부모 노드 상속\n",
    "        super().__init__()\n",
    "        # 함수를 변수에 저장하는 방식 - self.linear 변수에 nn.Linear 함수를 할당\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        \n",
    "    # 모델의 순전파 정의\n",
    "    def forward(self, X):\n",
    "        out = self.linear(X) # 선형 회귀 모델 사용\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = LinearRegression(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e129109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 모델\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # keras에서 레이어를 쌓아가듯이 함수를 쌓아주는 방식\n",
    "        out = self.linear(X)\n",
    "        out = self.Sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = LogisticRregression(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217e322",
   "metadata": {},
   "source": [
    "### 배치 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2275d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86dfe470",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = data_set['data'], data_set['target']\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af1c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치의 데이터로더를 사용하기 위해서는 데이터세트 자료구조로 바꿔주어야 한다.\n",
    "dset = TensorDataset(X, y)\n",
    "\n",
    "loader = DataLoader(dset, batch_size = 256, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aaf153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://velog.io/@seoyeonmmn/PyTorch-Tutorial-01.-Linear-Layer-nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c77bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_features, 4) # self.linear1 은 클래스에 대한 객체\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.linear1(X) # 선형 회귀\n",
    "        out = self.relu(out) # 활성화 함수(relu)\n",
    "        out = self.linear2(out) # 선형 회귀\n",
    "        out = self.sigmoid(out) # 활성화 함수(sigmoid)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork(30)\n",
    "criterion = nn.BCELoss() # 이진 크로스 엔트로피 손실함수(Binary Cross Entropy Loss Function)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1) # 확률적 경사 하강법 (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9e702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46240512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.1\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d33ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad() # 학습 시작시에 기울기를 초기화하는 작업\n",
    "        hypothesis = model(X_batch) # 1차적인 모델 학습 결과\n",
    "        loss = criterion(hypothesis, y_batch) # 1차적인 모델 학습의 결과와 라벨 값을 비교하여 손실값 계산\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(loader) # 평균 손실값 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cd185e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.5859\n",
      "epoch: 20, loss: 0.4699\n",
      "epoch: 30, loss: 0.3755\n",
      "epoch: 40, loss: 0.3269\n",
      "epoch: 50, loss: 0.2931\n",
      "epoch: 60, loss: 0.2639\n",
      "epoch: 70, loss: 0.2439\n",
      "epoch: 80, loss: 0.2469\n",
      "epoch: 90, loss: 0.2305\n",
      "epoch: 100, loss: 0.2109\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(model, criterion, optimizer, loader)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d3cd367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "y_predicted = (model(X) >= 0.5).float()\n",
    "\n",
    "score = (y_predicted == y).float().mean()\n",
    "print('accuracy: {:.2f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b895a0",
   "metadata": {},
   "source": [
    "### 모델 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c26d743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of trained model: 0.92\n"
     ]
    }
   ],
   "source": [
    "y_predicted_1 = (model(X) >= 0.5).float()\n",
    "\n",
    "score_of_trained_model = (y_predicted_1 == y).float().mean()\n",
    "print('accuracy of trained model: {:.2f}'.format(score_of_trained_model))\n",
    "\n",
    "# 학습한 모델의 가중치 저장\n",
    "torch.save(model.state_dict(), './data/trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5a77f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of loaded model: 0.92\n"
     ]
    }
   ],
   "source": [
    "load_model = NeuralNetwork(30)\n",
    "load_model.load_state_dict(torch.load('./data/trained_model.pt'))\n",
    "\n",
    "y_predicted_2 = (load_model(X) >= 0.5).float()\n",
    "\n",
    "score_of_load_model = (y_predicted_2 == y).float().mean()\n",
    "print('accuracy of loaded model: {:.2f}'.format(score_of_load_model))\n",
    "\n",
    "# 결국 학습의 결과물은 '가중치'.\n",
    "# 위에서 학습한 모델의 가중치를 저장한 후에, 해당 가중치를 그대로 읽어와 새로운 모델에 적용했으므로, 둘의 결과는 동일하게 나온다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
